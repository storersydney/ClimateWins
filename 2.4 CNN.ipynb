{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3589eb14-2374-4464-a23b-437d9a458ca8",
   "metadata": {},
   "source": [
    "## Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d001053-d6da-4dd2-88d8-9bd3ca133d3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers.scikit_learn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ModelCheckpoint\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m floor\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_scorer, accuracy_score\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers.scikit_learn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import operator\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import scikeras\n",
    "from numpy import unique\n",
    "from numpy import reshape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Dense, Dropout, BatchNormalization, Flatten, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical  # np_utils is deprecated\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc84b81-4fcf-4408-8f7e-f5f15d7a4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\sstorer\\OneDrive\\ML Specialization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caea247b-ca15-4d8e-809e-79da3913c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate = pd.read_csv(os.path.join(path, 'Data Sets', 'weather_cleaned.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a12340e-9d9c-4df8-966e-17bda0455dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pleasantweather = pd.read_csv(os.path.join(path, 'Data Sets', 'Dataset-Answers-Weather_Prediction_Pleasant_Weather.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f635c2-e315-4ab5-b583-0b83d9337371",
   "metadata": {},
   "outputs": [],
   "source": [
    "pleasantweather.drop(['DATE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f022291b-71a8-4c5f-b627-bcf1eb86f818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 135)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce164c6f-0a78-44d2-9dbb-7c104f268e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pleasantweather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717abc30-d5e6-4d15-93ce-0581d14182e0",
   "metadata": {},
   "source": [
    "## Reshaping for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54517087-4766-4300-b443-e53574d6f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn X and answers from df to arrays\n",
    "\n",
    "X = np.array(climate)\n",
    "y = np.array(pleasantweather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d0336cb-73ef-47f6-97af-ba8d6dca1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1,15,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2c108d6-2779-4237-8f0a-60364ccffc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b73309cf-5a74-4bf0-a5d5-964981468ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use argmax to transform y\n",
    "\n",
    "y =  np.argmax(y, axis = 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e0ea377-5685-4a88-9365-2f9ceb05cc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d117c80c-1b3a-4d5e-852a-c46d2f0d31c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiclass'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check y layout\n",
    "\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "type_of_target(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77e0ac-86e5-4817-b170-a525b91f9db8",
   "metadata": {},
   "source": [
    "## Splitting Data into Testing and Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f5680f-9ed7-4031-8e34-0d00c6ebf067",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b2b959-b84b-4fbd-a8ac-df39e12295b7",
   "metadata": {},
   "source": [
    "## Bayesian Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bdcace8-a85a-4a75-a013-47696e900044",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15 # Number of weather stations\n",
    "# Make scorer accuracy\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fda1558-1f4a-482b-93fc-dd2375b3be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "\n",
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2, normalization, dropout, dropout_rate): \n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    #optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
    "                 #'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
    "                 #'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
    "                 #'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU,'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]  #optimizerD[optimizerL[round(optimizer)]]\n",
    "    optimizer = optimizerL[round(optimizer)]\n",
    "    batch_size = round(batch_size)\n",
    "    \n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n",
    "        #model.add(Conv1D(32, kernel_size=1,activation='relu', input_shape=(timesteps, input_dim)))\n",
    "        \n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation)) #(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax')) #sigmoid softmax\n",
    "        #model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        return model\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=2, patience=20)\n",
    "    nn = KerasClassifier(build_fn=cnn_model, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ab7e176-4d27-4f4a-b8cd-e3ff3ab98368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class KerasClassifierCustom(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, build_fn, epochs=10, batch_size=32, verbose=2, **kwargs):\n",
    "        self.build_fn = build_fn\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = self.build_fn(**self.kwargs)\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.model.predict(X) > 0.5).astype(\"int32\")\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85d13b04-74f9-48a1-bbe9-735404b0389a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  kernel   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run Bayesian Optimization\u001b[39;00m\n\u001b[0;32m     17\u001b[0m nn_opt \u001b[38;5;241m=\u001b[39m BayesianOptimization(bay_area, params, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mnn_opt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearch took \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py:338\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter)\u001b[0m\n\u001b[0;32m    336\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest()\n\u001b[0;32m    337\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_probe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py:270\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mappend(params)\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\bayes_opt\\target_space.py:418\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    416\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo target function has been provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[1;32m--> 418\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdict_params)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[1;32mIn[24], line 45\u001b[0m, in \u001b[0;36mbay_area\u001b[1;34m(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs, layers1, layers2, normalization, dropout, dropout_rate)\u001b[0m\n\u001b[0;32m     43\u001b[0m nn \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39mcnn_model, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     44\u001b[0m kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:347\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m indexable(X, y)\n\u001b[0;32m    346\u001b[0m params \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m params\n\u001b[1;32m--> 347\u001b[0m cv \u001b[38;5;241m=\u001b[39m check_cv(cv, y, classifier\u001b[38;5;241m=\u001b[39m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    349\u001b[0m scorers \u001b[38;5;241m=\u001b[39m check_scoring(\n\u001b[0;32m    350\u001b[0m     estimator, scoring\u001b[38;5;241m=\u001b[39mscoring, raise_exc\u001b[38;5;241m=\u001b[39m(error_score \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    351\u001b[0m )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;66;03m# For estimators, a MetadataRouter is created in get_metadata_routing\u001b[39;00m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;66;03m# methods. For these router methods, we create the router to use\u001b[39;00m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# `process_routing` on it.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\base.py:1237\u001b[0m, in \u001b[0;36mis_classifier\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect\u001b[38;5;241m.\u001b[39mstack()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1233\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1234\u001b[0m     )\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_estimator_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\utils\\_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[1;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\base.py:540\u001b[0m, in \u001b[0;36mClassifierMixin.__sklearn_tags__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[0;32m    541\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m     tags\u001b[38;5;241m.\u001b[39mclassifier_tags \u001b[38;5;241m=\u001b[39m ClassifierTags()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "params ={\n",
    "    'neurons': (10, 100),\n",
    "    'kernel': (1, 3),\n",
    "    'activation':(0, 9), \n",
    "    'optimizer':(0,7),\n",
    "    'learning_rate':(0.01, 1),\n",
    "    'batch_size': (200, 1000), \n",
    "    'epochs':(20, 50),\n",
    "    'layers1':(1,3),\n",
    "    'layers2':(1,3),\n",
    "    'normalization':(0,1),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0,0.3)\n",
    "}\n",
    "# Run Bayesian Optimization\n",
    "nn_opt = BayesianOptimization(bay_area, params, random_state=42)\n",
    "nn_opt.maximize(init_points=15, n_iter=4) \n",
    "print('Search took %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32289d11-035d-4835-a506-0b83652f5084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "\n",
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2, normalization, dropout, dropout_rate): \n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    #optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
    "                 #'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
    "                 #'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
    "                 #'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU,'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]  #optimizerD[optimizerL[round(optimizer)]]\n",
    "    optimizer = optimizerL[round(optimizer)]\n",
    "    batch_size = round(batch_size)\n",
    "    \n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n",
    "        #model.add(Conv1D(32, kernel_size=1,activation='relu', input_shape=(timesteps, input_dim)))\n",
    "        \n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation)) #(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax')) #sigmoid softmax\n",
    "        #model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        return model\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=2, patience=20)\n",
    "    nn = KerasClassifierCustom(build_fn=cnn_model, epochs=10, batch_size=32, verbose=2)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ea2b868-3744-4827-8f13-f6999e11ecf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  kernel   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\sstorer\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\nTypeError: KerasClassifierCustom.fit() got an unexpected keyword argument 'callbacks'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run Bayesian Optimization\u001b[39;00m\n\u001b[0;32m     17\u001b[0m nn_opt \u001b[38;5;241m=\u001b[39m BayesianOptimization(bay_area, params, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mnn_opt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearch took \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py:338\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter)\u001b[0m\n\u001b[0;32m    336\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest()\n\u001b[0;32m    337\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_probe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py:270\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mappend(params)\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\bayes_opt\\target_space.py:418\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    416\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo target function has been provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[1;32m--> 418\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdict_params)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[1;32mIn[38], line 45\u001b[0m, in \u001b[0;36mbay_area\u001b[1;34m(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs, layers1, layers2, normalization, dropout, dropout_rate)\u001b[0m\n\u001b[0;32m     43\u001b[0m nn \u001b[38;5;241m=\u001b[39m KerasClassifierCustom(build_fn\u001b[38;5;241m=\u001b[39mcnn_model, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     44\u001b[0m kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:431\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    411\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    412\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    413\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    429\u001b[0m )\n\u001b[1;32m--> 431\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    516\u001b[0m     )\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\sstorer\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\nTypeError: KerasClassifierCustom.fit() got an unexpected keyword argument 'callbacks'\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "params ={\n",
    "    'neurons': (10, 100),\n",
    "    'kernel': (1, 3),\n",
    "    'activation':(0, 9), \n",
    "    'optimizer':(0,7),\n",
    "    'learning_rate':(0.01, 1),\n",
    "    'batch_size': (200, 1000), \n",
    "    'epochs':(20, 50),\n",
    "    'layers1':(1,3),\n",
    "    'layers2':(1,3),\n",
    "    'normalization':(0,1),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0,0.3)\n",
    "}\n",
    "# Run Bayesian Optimization\n",
    "nn_opt = BayesianOptimization(bay_area, params, random_state=42)\n",
    "nn_opt.maximize(init_points=15, n_iter=4) \n",
    "print('Search took %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98386529-eea7-420b-bdc7-09ae6cf20255",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasClassifierCustom(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, build_fn, epochs=10, batch_size=32, verbose=2, **kwargs):\n",
    "        self.build_fn = build_fn\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def fit(self, X, y, callbacks=None):  # Accept callbacks here\n",
    "        self.model = self.build_fn(**self.kwargs)\n",
    "        \n",
    "        # If callbacks are passed, include them in the fit method\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose, callbacks=callbacks)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.model.predict(X) > 0.5).astype(\"int32\")\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f32ebb58-22cd-409a-ac5b-1bd80260fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "\n",
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2, normalization, dropout, dropout_rate): \n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    #optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
    "                 #'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
    "                 #'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
    "                 #'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU,'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]  #optimizerD[optimizerL[round(optimizer)]]\n",
    "    optimizer = optimizerL[round(optimizer)]\n",
    "    batch_size = round(batch_size)\n",
    "    \n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n",
    "        #model.add(Conv1D(32, kernel_size=1,activation='relu', input_shape=(timesteps, input_dim)))\n",
    "        \n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation)) #(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax')) #sigmoid softmax\n",
    "        #model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        return model\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=2, patience=20)\n",
    "    nn = KerasClassifierCustom(build_fn=cnn_model, epochs=10, batch_size=32, verbose=2)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4ba4413-f62f-4447-8984-6387ead71cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  kernel   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 8ms/step - accuracy: 0.6434 - loss: 2.6762\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 2.6165\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 2.3789\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.9074\n",
      "Epoch 5/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6440 - loss: 1.5269\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.3525\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.2803\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.2446\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.2241\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.2110\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.6427 - loss: 2.6763\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 2.6181\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 2.3905\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.9210\n",
      "Epoch 5/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6440 - loss: 1.5331\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.3547\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.2809\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.2447\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.2240\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.2110\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 8ms/step - accuracy: 0.6423 - loss: 2.6762\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 2.6067\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 2.3491\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.8929\n",
      "Epoch 5/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6439 - loss: 1.5269\n",
      "Epoch 6/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6439 - loss: 1.3531\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.2797\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.2436\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.2230\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.2100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 8ms/step - accuracy: 0.6423 - loss: 2.6757\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 2.6021\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 2.3343\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.8668\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.5086\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.3440\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.2746\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.2404\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.2209\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.2084\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.6422 - loss: 2.6752\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 2.5954\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 2.3150\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.8478\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.4999\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.3412\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.2736\n",
      "Epoch 8/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6439 - loss: 1.2402\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.2209\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.2086\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m3.371    \u001b[39m | \u001b[39m960.6    \u001b[39m | \u001b[39m0.732    \u001b[39m | \u001b[39m0.1796   \u001b[39m | \u001b[39m24.68    \u001b[39m | \u001b[39m1.312    \u001b[39m | \u001b[39m1.116    \u001b[39m | \u001b[39m2.732    \u001b[39m | \u001b[39m0.6051   \u001b[39m | \u001b[39m73.73    \u001b[39m | \u001b[39m0.02058  \u001b[39m | \u001b[39m6.789    \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6427 - loss: nan\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6431 - loss: nan\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: nan\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m7.492    \u001b[39m | \u001b[39m369.9    \u001b[39m | \u001b[39m0.1818   \u001b[39m | \u001b[39m0.05502  \u001b[39m | \u001b[39m29.13    \u001b[39m | \u001b[39m2.05     \u001b[39m | \u001b[39m1.864    \u001b[39m | \u001b[39m1.582    \u001b[39m | \u001b[39m0.6157   \u001b[39m | \u001b[39m22.55    \u001b[39m | \u001b[39m0.2921   \u001b[39m | \u001b[39m2.565    \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 4s - 9ms/step - accuracy: 0.7478 - loss: 0.7597\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8200 - loss: 0.5156\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8477 - loss: 0.4319\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8695 - loss: 0.3817\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8807 - loss: 0.3419\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8918 - loss: 0.3128\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8938 - loss: 0.3006\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9015 - loss: 0.2761\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9118 - loss: 0.2586\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9125 - loss: 0.2388\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 8ms/step - accuracy: 0.7467 - loss: 0.7585\n",
      "Epoch 2/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.8197 - loss: 0.5175\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8458 - loss: 0.4404\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8712 - loss: 0.3746\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8821 - loss: 0.3366\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8927 - loss: 0.3068\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8981 - loss: 0.2858\n",
      "Epoch 8/10\n",
      "431/431 - 2s - 3ms/step - accuracy: 0.9059 - loss: 0.2622\n",
      "Epoch 9/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.9148 - loss: 0.2439\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9190 - loss: 0.2272\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 8ms/step - accuracy: 0.7468 - loss: 0.7698\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8160 - loss: 0.5288\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8397 - loss: 0.4502\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8575 - loss: 0.4003\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8721 - loss: 0.3622\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8823 - loss: 0.3288\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8946 - loss: 0.2950\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9020 - loss: 0.2773\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9054 - loss: 0.2644\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9134 - loss: 0.2409\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 8ms/step - accuracy: 0.7430 - loss: 0.7633\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8198 - loss: 0.5157\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8451 - loss: 0.4397\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8633 - loss: 0.3818\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8805 - loss: 0.3400\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8902 - loss: 0.3090\n",
      "Epoch 7/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.8981 - loss: 0.2876\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9060 - loss: 0.2638\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9118 - loss: 0.2517\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9204 - loss: 0.2297\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 4s - 9ms/step - accuracy: 0.7506 - loss: 0.7370\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8234 - loss: 0.5080\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8499 - loss: 0.4290\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8629 - loss: 0.3893\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8755 - loss: 0.3522\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8874 - loss: 0.3219\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8921 - loss: 0.3017\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8966 - loss: 0.2847\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9099 - loss: 0.2544\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9111 - loss: 0.2418\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m4.105    \u001b[39m | \u001b[39m828.1    \u001b[39m | \u001b[39m0.1997   \u001b[39m | \u001b[39m0.1543   \u001b[39m | \u001b[39m37.77    \u001b[39m | \u001b[39m1.093    \u001b[39m | \u001b[39m2.215    \u001b[39m | \u001b[39m1.341    \u001b[39m | \u001b[39m0.0744   \u001b[39m | \u001b[39m95.4     \u001b[39m | \u001b[39m0.9656   \u001b[39m | \u001b[39m5.659    \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6289 - loss: 1.4689\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.1414\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: 1.0952\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6441 - loss: 1.0711\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6441 - loss: 1.0541\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6457 - loss: 1.0408\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6467 - loss: 1.0298\n",
      "Epoch 8/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6500 - loss: 1.0193\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6570 - loss: 1.0087\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6616 - loss: 0.9977\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6016 - loss: 1.5704\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.1334\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6442 - loss: 1.0840\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6457 - loss: 1.0581\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6490 - loss: 1.0392\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6529 - loss: 1.0234\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6577 - loss: 1.0092\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6611 - loss: 0.9951\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6641 - loss: 0.9805\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6725 - loss: 0.9662\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6272 - loss: 1.5069\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.1360\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6443 - loss: 1.0824\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6466 - loss: 1.0577\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6542 - loss: 1.0426\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6532 - loss: 1.0310\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6573 - loss: 1.0221\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6581 - loss: 1.0138\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6615 - loss: 1.0057\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6608 - loss: 0.9987\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6232 - loss: 1.5332\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: 1.1591\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: 1.1115\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: 1.0839\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: 1.0638\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6445 - loss: 1.0482\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6473 - loss: 1.0354\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6519 - loss: 1.0245\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6550 - loss: 1.0155\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6574 - loss: 1.0072\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6266 - loss: 1.4861\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: 1.1358\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6443 - loss: 1.0857\n",
      "Epoch 4/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6459 - loss: 1.0607\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6497 - loss: 1.0435\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6553 - loss: 1.0295\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6598 - loss: 1.0166\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6590 - loss: 1.0053\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6649 - loss: 0.9927\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6670 - loss: 0.9810\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m2.742    \u001b[39m | \u001b[39m278.1    \u001b[39m | \u001b[39m0.6842   \u001b[39m | \u001b[39m0.132    \u001b[39m | \u001b[39m23.66    \u001b[39m | \u001b[39m1.99     \u001b[39m | \u001b[39m1.069    \u001b[39m | \u001b[39m2.819    \u001b[39m | \u001b[39m0.2662   \u001b[39m | \u001b[39m69.63    \u001b[39m | \u001b[39m0.3117   \u001b[39m | \u001b[39m3.64     \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6805 - loss: 0.9543\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7469 - loss: 0.7250\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7640 - loss: 0.6687\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7789 - loss: 0.6249\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7886 - loss: 0.5920\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8009 - loss: 0.5617\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8123 - loss: 0.5392\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8173 - loss: 0.5167\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8261 - loss: 0.4945\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8290 - loss: 0.4827\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6786 - loss: 0.9678\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7474 - loss: 0.7292\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7686 - loss: 0.6640\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7812 - loss: 0.6176\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7924 - loss: 0.5855\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8065 - loss: 0.5554\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8133 - loss: 0.5232\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8256 - loss: 0.4922\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8301 - loss: 0.4738\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8401 - loss: 0.4528\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6839 - loss: 0.9600\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7449 - loss: 0.7429\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7667 - loss: 0.6771\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7804 - loss: 0.6271\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7947 - loss: 0.5860\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8038 - loss: 0.5524\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8155 - loss: 0.5257\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8249 - loss: 0.4972\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8352 - loss: 0.4718\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8404 - loss: 0.4480\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6742 - loss: 0.9593\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7430 - loss: 0.7363\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7641 - loss: 0.6646\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7822 - loss: 0.6241\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7891 - loss: 0.5995\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7944 - loss: 0.5705\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8048 - loss: 0.5522\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8119 - loss: 0.5330\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8190 - loss: 0.5108\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8242 - loss: 0.4957\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.6774 - loss: 0.9801\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7365 - loss: 0.7413\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7635 - loss: 0.6646\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7823 - loss: 0.6237\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7898 - loss: 0.5980\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7980 - loss: 0.5707\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8050 - loss: 0.5494\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8114 - loss: 0.5274\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8200 - loss: 0.5020\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8277 - loss: 0.4842\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m4.92     \u001b[39m | \u001b[39m347.9    \u001b[39m | \u001b[39m0.9696   \u001b[39m | \u001b[39m0.2325   \u001b[39m | \u001b[39m48.18    \u001b[39m | \u001b[39m2.79     \u001b[39m | \u001b[39m2.196    \u001b[39m | \u001b[39m2.844    \u001b[39m | \u001b[39m0.09761  \u001b[39m | \u001b[39m27.64    \u001b[39m | \u001b[39m0.04523  \u001b[39m | \u001b[39m2.277    \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 4s - 8ms/step - accuracy: 0.7357 - loss: 0.7905\n",
      "Epoch 2/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.8027 - loss: 0.5757\n",
      "Epoch 3/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.8237 - loss: 0.5050\n",
      "Epoch 4/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.8401 - loss: 0.4589\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8528 - loss: 0.4092\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8630 - loss: 0.3858\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8752 - loss: 0.3492\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8858 - loss: 0.3269\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8914 - loss: 0.3098\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8992 - loss: 0.2917\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 8ms/step - accuracy: 0.7427 - loss: 0.7687\n",
      "Epoch 2/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.8098 - loss: 0.5468\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8313 - loss: 0.4755\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8486 - loss: 0.4259\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8605 - loss: 0.3965\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8693 - loss: 0.3695\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8796 - loss: 0.3368\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8863 - loss: 0.3272\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8943 - loss: 0.2958\n",
      "Epoch 10/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.9017 - loss: 0.2844\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 4s - 9ms/step - accuracy: 0.7346 - loss: 0.8015\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7954 - loss: 0.5901\n",
      "Epoch 3/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.8237 - loss: 0.4964\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8423 - loss: 0.4440\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8583 - loss: 0.3937\n",
      "Epoch 6/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.8705 - loss: 0.3673\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8829 - loss: 0.3343\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8877 - loss: 0.3126\n",
      "Epoch 9/10\n",
      "431/431 - 2s - 3ms/step - accuracy: 0.8965 - loss: 0.2945\n",
      "Epoch 10/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.8989 - loss: 0.2858\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 8ms/step - accuracy: 0.7361 - loss: 0.7873\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8015 - loss: 0.5742\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8227 - loss: 0.5023\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8376 - loss: 0.4464\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8562 - loss: 0.4091\n",
      "Epoch 6/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.8672 - loss: 0.3728\n",
      "Epoch 7/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.8762 - loss: 0.3488\n",
      "Epoch 8/10\n",
      "431/431 - 2s - 6ms/step - accuracy: 0.8870 - loss: 0.3251\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8954 - loss: 0.2926\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8985 - loss: 0.2914\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 8ms/step - accuracy: 0.7351 - loss: 0.7974\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7989 - loss: 0.5735\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8267 - loss: 0.4888\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8452 - loss: 0.4329\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8541 - loss: 0.4095\n",
      "Epoch 6/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.8751 - loss: 0.3635\n",
      "Epoch 7/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.8810 - loss: 0.3405\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8874 - loss: 0.3214\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9007 - loss: 0.2879\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9018 - loss: 0.2806\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m3.498    \u001b[39m | \u001b[39m417.1    \u001b[39m | \u001b[39m0.8287   \u001b[39m | \u001b[39m0.107    \u001b[39m | \u001b[39m28.43    \u001b[39m | \u001b[39m2.085    \u001b[39m | \u001b[39m1.282    \u001b[39m | \u001b[39m2.604    \u001b[39m | \u001b[39m0.08381  \u001b[39m | \u001b[39m98.82    \u001b[39m | \u001b[39m0.7722   \u001b[39m | \u001b[39m1.391    \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6588 - loss: 0.9983\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6974 - loss: 0.8627\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7109 - loss: 0.8181\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7245 - loss: 0.7933\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7307 - loss: 0.7716\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7407 - loss: 0.7564\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7447 - loss: 0.7435\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7462 - loss: 0.7317\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7460 - loss: 0.7234\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7571 - loss: 0.7064\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6671 - loss: 0.9736\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7048 - loss: 0.8434\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7221 - loss: 0.7989\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7330 - loss: 0.7765\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7345 - loss: 0.7595\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7445 - loss: 0.7428\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7467 - loss: 0.7317\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7494 - loss: 0.7169\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7554 - loss: 0.7055\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7628 - loss: 0.6910\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6782 - loss: 0.9698\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7114 - loss: 0.8370\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7269 - loss: 0.8044\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7311 - loss: 0.7848\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7362 - loss: 0.7657\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7413 - loss: 0.7491\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7448 - loss: 0.7387\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7500 - loss: 0.7239\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7532 - loss: 0.7140\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7571 - loss: 0.7022\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6591 - loss: 1.0236\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7043 - loss: 0.8641\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7201 - loss: 0.8165\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7235 - loss: 0.7923\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7329 - loss: 0.7696\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7363 - loss: 0.7587\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7426 - loss: 0.7445\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7428 - loss: 0.7361\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7455 - loss: 0.7200\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7522 - loss: 0.7081\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6622 - loss: 1.0073\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7034 - loss: 0.8564\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7148 - loss: 0.8183\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7246 - loss: 0.7947\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7290 - loss: 0.7822\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7347 - loss: 0.7657\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7392 - loss: 0.7469\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7460 - loss: 0.7326\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7470 - loss: 0.7211\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7546 - loss: 0.7087\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m0.0497   \u001b[39m | \u001b[39m852.4    \u001b[39m | \u001b[39m0.7069   \u001b[39m | \u001b[39m0.2187   \u001b[39m | \u001b[39m43.14    \u001b[39m | \u001b[39m1.148    \u001b[39m | \u001b[39m1.717    \u001b[39m | \u001b[39m1.232    \u001b[39m | \u001b[39m0.8645   \u001b[39m | \u001b[39m66.1     \u001b[39m | \u001b[39m0.3309   \u001b[39m | \u001b[39m0.4449   \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.1149 - loss: 2.5958\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.2092 - loss: 2.5124\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.3421 - loss: 2.4232\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.4628 - loss: 2.3306\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.5430 - loss: 2.2348\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.5904 - loss: 2.1406\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6172 - loss: 2.0498\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6325 - loss: 1.9597\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6406 - loss: 1.8709\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6441 - loss: 1.7869\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.2814 - loss: 2.4897\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.3788 - loss: 2.4115\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.4683 - loss: 2.3280\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.5182 - loss: 2.2404\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.5438 - loss: 2.1535\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.5637 - loss: 2.0656\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.5743 - loss: 1.9808\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.5868 - loss: 1.8956\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.5930 - loss: 1.8140\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6000 - loss: 1.7372\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.1101 - loss: 2.6750\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.1943 - loss: 2.5912\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.2983 - loss: 2.5048\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.4378 - loss: 2.4113\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.5463 - loss: 2.3200\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6125 - loss: 2.2259\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6424 - loss: 2.1333\n",
      "Epoch 8/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6537 - loss: 2.0402\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6576 - loss: 1.9511\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6544 - loss: 1.8641\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.0498 - loss: 2.7867\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.0667 - loss: 2.7069\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.1006 - loss: 2.6232\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.1542 - loss: 2.5391\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.2375 - loss: 2.4527\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.3336 - loss: 2.3652\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.4206 - loss: 2.2791\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.4987 - loss: 2.1924\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.5529 - loss: 2.1080\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.5848 - loss: 2.0252\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.0296 - loss: 2.7501\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.0670 - loss: 2.6661\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.1378 - loss: 2.5767\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.2380 - loss: 2.4885\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.3445 - loss: 2.3969\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.4326 - loss: 2.3055\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.5095 - loss: 2.2128\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.5546 - loss: 2.1248\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.5882 - loss: 2.0356\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6110 - loss: 1.9514\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m2.799    \u001b[39m | \u001b[39m460.1    \u001b[39m | \u001b[39m0.7296   \u001b[39m | \u001b[39m0.1913   \u001b[39m | \u001b[39m46.62    \u001b[39m | \u001b[39m1.944    \u001b[39m | \u001b[39m1.239    \u001b[39m | \u001b[39m2.426    \u001b[39m | \u001b[39m0.7632   \u001b[39m | \u001b[39m60.51    \u001b[39m | \u001b[39m0.771    \u001b[39m | \u001b[39m3.457    \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6844 - loss: 0.9698\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7445 - loss: 0.7839\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7621 - loss: 0.7147\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7726 - loss: 0.6766\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7816 - loss: 0.6378\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7907 - loss: 0.6118\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7965 - loss: 0.5894\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8017 - loss: 0.5694\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8067 - loss: 0.5463\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8123 - loss: 0.5313\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6786 - loss: 0.9617\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7422 - loss: 0.7818\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7635 - loss: 0.7161\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7716 - loss: 0.6723\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7833 - loss: 0.6301\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7933 - loss: 0.6048\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7985 - loss: 0.5795\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8017 - loss: 0.5598\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8081 - loss: 0.5420\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8137 - loss: 0.5241\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6821 - loss: 0.9474\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7391 - loss: 0.7687\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7597 - loss: 0.7038\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7757 - loss: 0.6604\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7860 - loss: 0.6259\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7924 - loss: 0.5974\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8015 - loss: 0.5719\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8092 - loss: 0.5521\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8131 - loss: 0.5349\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8177 - loss: 0.5185\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6721 - loss: 0.9724\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7367 - loss: 0.7882\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7600 - loss: 0.7184\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7736 - loss: 0.6772\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7820 - loss: 0.6421\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7903 - loss: 0.6149\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7921 - loss: 0.5931\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8004 - loss: 0.5712\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8041 - loss: 0.5554\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8095 - loss: 0.5404\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.6808 - loss: 0.9740\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7357 - loss: 0.8082\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7527 - loss: 0.7467\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7641 - loss: 0.7058\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7771 - loss: 0.6708\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7813 - loss: 0.6424\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7886 - loss: 0.6190\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7954 - loss: 0.5951\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8014 - loss: 0.5785\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8065 - loss: 0.5600\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m4.705    \u001b[39m | \u001b[39m542.0    \u001b[39m | \u001b[39m0.02542  \u001b[39m | \u001b[39m0.03237  \u001b[39m | \u001b[39m20.94    \u001b[39m | \u001b[39m2.273    \u001b[39m | \u001b[39m1.629    \u001b[39m | \u001b[39m2.017    \u001b[39m | \u001b[39m0.9085   \u001b[39m | \u001b[39m32.44    \u001b[39m | \u001b[39m0.4104   \u001b[39m | \u001b[39m5.289    \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.5398 - loss: 1.5940\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.1404\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.1027\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.0793\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.0646\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.0540\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.0478\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6446 - loss: 1.0401\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6452 - loss: 1.0356\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6464 - loss: 1.0303\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 6ms/step - accuracy: 0.6241 - loss: 1.2596\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.1172\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.0887\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: 1.0694\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6437 - loss: 1.0588\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6436 - loss: 1.0503\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.0435\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6460 - loss: 1.0382\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6470 - loss: 1.0331\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6462 - loss: 1.0294\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 6ms/step - accuracy: 0.6256 - loss: 1.3521\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.1623\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.1431\n",
      "Epoch 4/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6439 - loss: 1.1274\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.1105\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.0910\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.0702\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.0511\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6442 - loss: 1.0347\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6450 - loss: 1.0205\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6205 - loss: 1.2549\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: 1.1286\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: 1.1000\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.0813\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.0695\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.0605\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6442 - loss: 1.0534\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6449 - loss: 1.0457\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6460 - loss: 1.0384\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6510 - loss: 1.0298\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6192 - loss: 1.3495\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.1683\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.1475\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.1297\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.1093\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6450 - loss: 1.0874\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6505 - loss: 1.0657\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6582 - loss: 1.0462\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6642 - loss: 1.0335\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6674 - loss: 1.0207\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m2.059    \u001b[39m | \u001b[39m261.6    \u001b[39m | \u001b[39m0.2898   \u001b[39m | \u001b[39m0.04837  \u001b[39m | \u001b[39m47.89    \u001b[39m | \u001b[39m2.616    \u001b[39m | \u001b[39m2.267    \u001b[39m | \u001b[39m2.743    \u001b[39m | \u001b[39m0.8056   \u001b[39m | \u001b[39m26.79    \u001b[39m | \u001b[39m0.8926   \u001b[39m | \u001b[39m3.775    \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6425 - loss: nan\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 2/10\n",
      "431/431 - 3s - 8ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/10\n",
      "431/431 - 2s - 6ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/10\n",
      "431/431 - 2s - 3ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: nan\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.6427 - loss: nan\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 3/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 4/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 5/10\n",
      "431/431 - 2s - 6ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: nan\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 4/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: nan\n",
      "Epoch 10/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.6439 - loss: nan\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m7.267    \u001b[39m | \u001b[39m916.9    \u001b[39m | \u001b[39m0.318    \u001b[39m | \u001b[39m0.03302  \u001b[39m | \u001b[39m26.84    \u001b[39m | \u001b[39m1.854    \u001b[39m | \u001b[39m2.636    \u001b[39m | \u001b[39m2.721    \u001b[39m | \u001b[39m0.01688  \u001b[39m | \u001b[39m55.97    \u001b[39m | \u001b[39m0.4174   \u001b[39m | \u001b[39m1.555    \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6405 - loss: 1.1883\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: 1.1697\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: 1.1673\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.1291\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6442 - loss: 1.0232\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6437 - loss: 0.9880\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6461 - loss: 0.9553\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6715 - loss: 0.8927\n",
      "Epoch 9/10\n",
      "431/431 - 6s - 14ms/step - accuracy: 0.7083 - loss: 0.8213\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7188 - loss: 0.7800\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6412 - loss: 1.1940\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.1696\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6440 - loss: 1.1514\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6438 - loss: 1.0346\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6425 - loss: 0.9899\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6427 - loss: 0.9566\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6633 - loss: 0.9083\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6981 - loss: 0.8389\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7237 - loss: 0.7762\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7360 - loss: 0.7411\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6365 - loss: 1.1971\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6439 - loss: 1.1709\n",
      "Epoch 3/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6439 - loss: 1.1599\n",
      "Epoch 4/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6440 - loss: 1.0377\n",
      "Epoch 5/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.6424 - loss: 0.9886\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6493 - loss: 0.9364\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6832 - loss: 0.8631\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7078 - loss: 0.8016\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7218 - loss: 0.7614\n",
      "Epoch 10/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.7324 - loss: 0.7327\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.6412 - loss: 1.1874\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: 1.1695\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6440 - loss: 1.1271\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6427 - loss: 0.9997\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6519 - loss: 0.9364\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.6967 - loss: 0.8579\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7224 - loss: 0.7926\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7355 - loss: 0.7504\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7428 - loss: 0.7251\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7475 - loss: 0.7057\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.6384 - loss: 1.1918\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6439 - loss: 1.1671\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6414 - loss: 1.0600\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6415 - loss: 0.9820\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6577 - loss: 0.9253\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.6954 - loss: 0.8563\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7206 - loss: 0.7921\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7344 - loss: 0.7509\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7420 - loss: 0.7200\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7455 - loss: 0.7033\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m1.079    \u001b[39m | \u001b[39m470.1    \u001b[39m | \u001b[39m0.9429   \u001b[39m | \u001b[39m0.09696  \u001b[39m | \u001b[39m35.56    \u001b[39m | \u001b[39m2.406    \u001b[39m | \u001b[39m1.727    \u001b[39m | \u001b[39m2.944    \u001b[39m | \u001b[39m0.9628   \u001b[39m | \u001b[39m32.66    \u001b[39m | \u001b[39m0.4972   \u001b[39m | \u001b[39m2.106    \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 2s - 6ms/step - accuracy: 0.7202 - loss: 0.8374\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7806 - loss: 0.6522\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8045 - loss: 0.5766\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8212 - loss: 0.5208\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8332 - loss: 0.4816\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8420 - loss: 0.4514\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8592 - loss: 0.4114\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8633 - loss: 0.3976\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8714 - loss: 0.3783\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8797 - loss: 0.3545\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.7213 - loss: 0.8533\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7722 - loss: 0.6632\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7956 - loss: 0.5846\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8107 - loss: 0.5365\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8246 - loss: 0.4952\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8362 - loss: 0.4606\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8473 - loss: 0.4320\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8581 - loss: 0.4033\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8648 - loss: 0.3841\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8697 - loss: 0.3652\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.7138 - loss: 0.8619\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7765 - loss: 0.6592\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7974 - loss: 0.5840\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8235 - loss: 0.5200\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8328 - loss: 0.4843\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8439 - loss: 0.4563\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8517 - loss: 0.4252\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8599 - loss: 0.4098\n",
      "Epoch 9/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.8693 - loss: 0.3763\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8752 - loss: 0.3643\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.7214 - loss: 0.8434\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7766 - loss: 0.6535\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7969 - loss: 0.5860\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8168 - loss: 0.5291\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8341 - loss: 0.4872\n",
      "Epoch 6/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.8467 - loss: 0.4463\n",
      "Epoch 7/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.8540 - loss: 0.4189\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8648 - loss: 0.3907\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8754 - loss: 0.3647\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8813 - loss: 0.3508\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.7161 - loss: 0.8602\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7776 - loss: 0.6586\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7985 - loss: 0.5872\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8144 - loss: 0.5363\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8312 - loss: 0.4846\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8427 - loss: 0.4535\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8516 - loss: 0.4267\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8644 - loss: 0.3983\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8694 - loss: 0.3787\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8770 - loss: 0.3620\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m2.564    \u001b[39m | \u001b[39m229.5    \u001b[39m | \u001b[39m0.6096   \u001b[39m | \u001b[39m0.1508   \u001b[39m | \u001b[39m21.54    \u001b[39m | \u001b[39m1.557    \u001b[39m | \u001b[39m2.817    \u001b[39m | \u001b[39m1.479    \u001b[39m | \u001b[39m0.1534   \u001b[39m | \u001b[39m54.05    \u001b[39m | \u001b[39m0.9857   \u001b[39m | \u001b[39m1.694    \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.7352 - loss: 0.7655\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7942 - loss: 0.5830\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8266 - loss: 0.4888\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8410 - loss: 0.4377\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8644 - loss: 0.3841\n",
      "Epoch 6/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.8754 - loss: 0.3463\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8798 - loss: 0.3291\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8996 - loss: 0.2763\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9014 - loss: 0.2764\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9118 - loss: 0.2576\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.7373 - loss: 0.7785\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7942 - loss: 0.5840\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8132 - loss: 0.5170\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8383 - loss: 0.4521\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8481 - loss: 0.4093\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8656 - loss: 0.3678\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8725 - loss: 0.3453\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8909 - loss: 0.3032\n",
      "Epoch 9/10\n",
      "431/431 - 2s - 5ms/step - accuracy: 0.8932 - loss: 0.2938\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9034 - loss: 0.2691\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.7377 - loss: 0.7907\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7866 - loss: 0.5995\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8122 - loss: 0.5297\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8280 - loss: 0.4719\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8422 - loss: 0.4263\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8611 - loss: 0.3811\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8719 - loss: 0.3517\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8823 - loss: 0.3201\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8892 - loss: 0.3052\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9024 - loss: 0.2751\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.7357 - loss: 0.7912\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7970 - loss: 0.5740\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8256 - loss: 0.4883\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8450 - loss: 0.4300\n",
      "Epoch 5/10\n",
      "431/431 - 2s - 4ms/step - accuracy: 0.8615 - loss: 0.3866\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8744 - loss: 0.3462\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8902 - loss: 0.3136\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8985 - loss: 0.2879\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9081 - loss: 0.2618\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9137 - loss: 0.2433\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.7340 - loss: 0.7751\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7893 - loss: 0.5903\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8207 - loss: 0.5001\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8408 - loss: 0.4365\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8548 - loss: 0.3939\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8677 - loss: 0.3588\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8795 - loss: 0.3310\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8849 - loss: 0.3157\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8939 - loss: 0.2974\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.9043 - loss: 0.2638\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m6.049    \u001b[39m | \u001b[39m809.3    \u001b[39m | \u001b[39m0.2376   \u001b[39m | \u001b[39m0.2185   \u001b[39m | \u001b[39m31.03    \u001b[39m | \u001b[39m2.265    \u001b[39m | \u001b[39m2.267    \u001b[39m | \u001b[39m2.072    \u001b[39m | \u001b[39m0.09939  \u001b[39m | \u001b[39m85.18    \u001b[39m | \u001b[39m0.3208   \u001b[39m | \u001b[39m1.306    \u001b[39m |\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 6ms/step - accuracy: 0.7086 - loss: 0.8644\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7815 - loss: 0.6269\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8206 - loss: 0.5151\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8402 - loss: 0.4486\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8622 - loss: 0.3984\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8751 - loss: 0.3676\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8820 - loss: 0.3416\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8906 - loss: 0.3180\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8955 - loss: 0.2997\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.9007 - loss: 0.2900\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.7125 - loss: 0.8529\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7803 - loss: 0.6348\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8229 - loss: 0.5072\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8460 - loss: 0.4406\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8681 - loss: 0.3881\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8774 - loss: 0.3570\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8869 - loss: 0.3301\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8948 - loss: 0.3074\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.9030 - loss: 0.2871\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.9055 - loss: 0.2739\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 4s - 9ms/step - accuracy: 0.7174 - loss: 0.8438\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7844 - loss: 0.6194\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8200 - loss: 0.5161\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8424 - loss: 0.4578\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8517 - loss: 0.4259\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8643 - loss: 0.3958\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8755 - loss: 0.3598\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8861 - loss: 0.3341\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8928 - loss: 0.3134\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8975 - loss: 0.3001\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.6988 - loss: 0.8775\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.7874 - loss: 0.6050\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8319 - loss: 0.4816\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8479 - loss: 0.4269\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8699 - loss: 0.3797\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8868 - loss: 0.3336\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8890 - loss: 0.3134\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8937 - loss: 0.3053\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.9062 - loss: 0.2725\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.9072 - loss: 0.2608\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "431/431 - 3s - 7ms/step - accuracy: 0.7150 - loss: 0.8541\n",
      "Epoch 2/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.7789 - loss: 0.6353\n",
      "Epoch 3/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8103 - loss: 0.5398\n",
      "Epoch 4/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8275 - loss: 0.4851\n",
      "Epoch 5/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8436 - loss: 0.4439\n",
      "Epoch 6/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8556 - loss: 0.4143\n",
      "Epoch 7/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8625 - loss: 0.3892\n",
      "Epoch 8/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8699 - loss: 0.3761\n",
      "Epoch 9/10\n",
      "431/431 - 1s - 3ms/step - accuracy: 0.8780 - loss: 0.3455\n",
      "Epoch 10/10\n",
      "431/431 - 1s - 2ms/step - accuracy: 0.8850 - loss: 0.3300\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m0.367    \u001b[39m | \u001b[39m672.7    \u001b[39m | \u001b[39m0.6776   \u001b[39m | \u001b[39m0.004976 \u001b[39m | \u001b[39m35.36    \u001b[39m | \u001b[39m1.453    \u001b[39m | \u001b[39m2.29     \u001b[39m | \u001b[39m1.349    \u001b[39m | \u001b[39m0.694    \u001b[39m | \u001b[39m44.81    \u001b[39m | \u001b[39m0.9367   \u001b[39m | \u001b[39m0.9626   \u001b[39m |\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py:334\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 334\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run Bayesian Optimization\u001b[39;00m\n\u001b[0;32m     17\u001b[0m nn_opt \u001b[38;5;241m=\u001b[39m BayesianOptimization(bay_area, params, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mnn_opt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearch took \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py:336\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter)\u001b[0m\n\u001b[0;32m    334\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py:279\u001b[0m, in \u001b[0;36mBayesianOptimization.suggest\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39marray_to_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mrandom_sample())\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# Finding argmax of the acquisition function.\u001b[39;00m\n\u001b[1;32m--> 279\u001b[0m suggestion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquisition_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_gp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39marray_to_params(suggestion)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\bayes_opt\\acquisition.py:414\u001b[0m, in \u001b[0;36mUpperConfidenceBound.suggest\u001b[1;34m(self, gp, target_space, n_random, n_l_bfgs_b, fit_gp)\u001b[0m\n\u001b[0;32m    409\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived constraints, but acquisition function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not support constrained optimization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m     )\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConstraintNotSupportedError(msg)\n\u001b[1;32m--> 414\u001b[0m x_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_random\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_l_bfgs_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_l_bfgs_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_gp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_gp\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay_exploration()\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_max\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\bayes_opt\\acquisition.py:127\u001b[0m, in \u001b[0;36mAcquisitionFunction.suggest\u001b[1;34m(self, gp, target_space, n_random, n_l_bfgs_b, fit_gp)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fit_gp:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_gp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m acq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_acq(gp\u001b[38;5;241m=\u001b[39mgp, constraint\u001b[38;5;241m=\u001b[39mtarget_space\u001b[38;5;241m.\u001b[39mconstraint)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acq_min(acq, target_space\u001b[38;5;241m.\u001b[39mbounds, n_random\u001b[38;5;241m=\u001b[39mn_random, n_l_bfgs_b\u001b[38;5;241m=\u001b[39mn_l_bfgs_b)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\bayes_opt\\acquisition.py:81\u001b[0m, in \u001b[0;36mAcquisitionFunction._fit_gp\u001b[1;34m(self, gp, target_space)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m     80\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 81\u001b[0m     \u001b[43mgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_space\u001b[38;5;241m.\u001b[39mconstraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m         target_space\u001b[38;5;241m.\u001b[39mconstraint\u001b[38;5;241m.\u001b[39mfit(target_space\u001b[38;5;241m.\u001b[39mparams, target_space\u001b[38;5;241m.\u001b[39m_constraint_values)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:251\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m     dtype, ensure_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m n_targets_seen \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n_targets_seen \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\utils\\validation.py:1387\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[0;32m   1370\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1371\u001b[0m     X,\n\u001b[0;32m   1372\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1384\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1385\u001b[0m )\n\u001b[1;32m-> 1387\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1389\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\utils\\validation.py:1397\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1397\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1407\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf-env\\lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "params ={\n",
    "    'neurons': (10, 100),\n",
    "    'kernel': (1, 3),\n",
    "    'activation':(0, 9), \n",
    "    'optimizer':(0,7),\n",
    "    'learning_rate':(0.01, 1),\n",
    "    'batch_size': (200, 1000), \n",
    "    'epochs':(20, 50),\n",
    "    'layers1':(1,3),\n",
    "    'layers2':(1,3),\n",
    "    'normalization':(0,1),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0,0.3)\n",
    "}\n",
    "# Run Bayesian Optimization\n",
    "nn_opt = BayesianOptimization(bay_area, params, random_state=42)\n",
    "nn_opt.maximize(init_points=15, n_iter=4) \n",
    "print('Search took %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1a991d2-62ed-4969-83de-10e73b7db90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softsign',\n",
       " 'batch_size': 961,\n",
       " 'dropout': np.float64(0.7319939418114051),\n",
       " 'dropout_rate': np.float64(0.17959754525911098),\n",
       " 'epochs': 25,\n",
       " 'kernel': np.float64(1.3119890406724053),\n",
       " 'layers1': 1,\n",
       " 'layers2': 3,\n",
       " 'learning_rate': np.float64(0.6051038616257767),\n",
       " 'neurons': 74,\n",
       " 'normalization': np.float64(0.020584494295802447),\n",
       " 'optimizer': <keras.src.optimizers.ftrl.Ftrl at 0x1b5977da410>}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum = nn_opt.max['params']\n",
    "learning_rate = optimum['learning_rate']\n",
    "\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', LeakyReLU, 'relu']\n",
    "optimum['activation'] = activationL[round(optimum['activation'])]\n",
    "\n",
    "optimum['batch_size'] = round(optimum['batch_size'])\n",
    "optimum['epochs'] = round(optimum['epochs'])\n",
    "optimum['layers1'] = round(optimum['layers1'])\n",
    "optimum['layers2'] = round(optimum['layers2'])\n",
    "optimum['neurons'] = round(optimum['neurons'])\n",
    "\n",
    "optimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl', 'Adam']\n",
    "optimizerD = {\n",
    "    'Adam': Adam(learning_rate=learning_rate),\n",
    "    'SGD': SGD(learning_rate=learning_rate),\n",
    "    'RMSprop': RMSprop(learning_rate=learning_rate),\n",
    "    'Adadelta': Adadelta(learning_rate=learning_rate),\n",
    "    'Adagrad': Adagrad(learning_rate=learning_rate),\n",
    "    'Adamax': Adamax(learning_rate=learning_rate),\n",
    "    'Nadam': Nadam(learning_rate=learning_rate),\n",
    "    'Ftrl': Ftrl(learning_rate=learning_rate)\n",
    "}\n",
    "optimum['optimizer'] = optimizerD[optimizerL[round(optimum['optimizer'])]]\n",
    "optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e2482-b519-4e88-8d8c-d1119623af8c",
   "metadata": {},
   "source": [
    "## Running CNN Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "031e60f0-3354-499c-be72-8775ad949ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model with optimized hyperparameters\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 961\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15\n",
    "\n",
    "layers1 = 1\n",
    "layers2 = 3\n",
    "activation = 'softsign'\n",
    "kernel = 1\n",
    "neurons = 74\n",
    "normalization = np.float64(0.020584494295802447)\n",
    "dropout = np.float64(0.7319939418114051)\n",
    "dropout_rate = np.float64(0.17959754525911098)\n",
    "optimizer = 'ftrl'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(neurons, kernel_size=kernel, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "\n",
    "if normalization > 0.5:\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "for i in range(layers1):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "if dropout > 0.5:\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "for i in range(layers2):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes, activation='softmax')) \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "587383bb-8d9d-4e55-9ae8-903187a5910d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_78\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_78\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">740</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_385 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_386 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_387 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_388 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">518</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_389 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,785</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_78 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m74\u001b[0m)         │           \u001b[38;5;34m740\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_385 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m74\u001b[0m)         │         \u001b[38;5;34m5,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m74\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_386 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m74\u001b[0m)         │         \u001b[38;5;34m5,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_387 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m74\u001b[0m)         │         \u001b[38;5;34m5,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_388 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m74\u001b[0m)         │         \u001b[38;5;34m5,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_76 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m74\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_76 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m518\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_389 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │         \u001b[38;5;34m7,785\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,725</span> (120.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,725\u001b[0m (120.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,725</span> (120.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,725\u001b[0m (120.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0da68758-8401-428c-ad6d-29a7a7d1f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the y_test set back into a one-hot configuration\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b684ade-3830-4a85-8ab2-eaf8eb224933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17212, 15, 9)\n",
      "y_train_one_hot shape: (17212, 15)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train_one_hot shape: {y_train_one_hot.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8dcf9d86-895b-4537-8ea4-a21d5684bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with categorical_crossentropy\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "00e7ead4-2d82-4547-956c-e417c339a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "18/18 - 3s - 159ms/step - accuracy: 0.6095 - loss: 2.7104\n",
      "Epoch 2/25\n",
      "18/18 - 1s - 37ms/step - accuracy: 0.6440 - loss: 2.6993\n",
      "Epoch 3/25\n",
      "18/18 - 1s - 40ms/step - accuracy: 0.6440 - loss: 2.6956\n",
      "Epoch 4/25\n",
      "18/18 - 1s - 37ms/step - accuracy: 0.6440 - loss: 2.6924\n",
      "Epoch 5/25\n",
      "18/18 - 1s - 37ms/step - accuracy: 0.6440 - loss: 2.6897\n",
      "Epoch 6/25\n",
      "18/18 - 1s - 35ms/step - accuracy: 0.6440 - loss: 2.6871\n",
      "Epoch 7/25\n",
      "18/18 - 1s - 37ms/step - accuracy: 0.6440 - loss: 2.6848\n",
      "Epoch 8/25\n",
      "18/18 - 1s - 37ms/step - accuracy: 0.6440 - loss: 2.6826\n",
      "Epoch 9/25\n",
      "18/18 - 1s - 35ms/step - accuracy: 0.6440 - loss: 2.6806\n",
      "Epoch 10/25\n",
      "18/18 - 1s - 35ms/step - accuracy: 0.6440 - loss: 2.6786\n",
      "Epoch 11/25\n",
      "18/18 - 1s - 36ms/step - accuracy: 0.6440 - loss: 2.6768\n",
      "Epoch 12/25\n",
      "18/18 - 1s - 37ms/step - accuracy: 0.6440 - loss: 2.6750\n",
      "Epoch 13/25\n",
      "18/18 - 1s - 36ms/step - accuracy: 0.6440 - loss: 2.6732\n",
      "Epoch 14/25\n",
      "18/18 - 1s - 36ms/step - accuracy: 0.6440 - loss: 2.6715\n",
      "Epoch 15/25\n",
      "18/18 - 1s - 36ms/step - accuracy: 0.6440 - loss: 2.6698\n",
      "Epoch 16/25\n",
      "18/18 - 1s - 35ms/step - accuracy: 0.6440 - loss: 2.6682\n",
      "Epoch 17/25\n",
      "18/18 - 1s - 35ms/step - accuracy: 0.6440 - loss: 2.6666\n",
      "Epoch 18/25\n",
      "18/18 - 1s - 34ms/step - accuracy: 0.6440 - loss: 2.6650\n",
      "Epoch 19/25\n",
      "18/18 - 1s - 35ms/step - accuracy: 0.6440 - loss: 2.6634\n",
      "Epoch 20/25\n",
      "18/18 - 1s - 36ms/step - accuracy: 0.6440 - loss: 2.6618\n",
      "Epoch 21/25\n",
      "18/18 - 1s - 36ms/step - accuracy: 0.6440 - loss: 2.6602\n",
      "Epoch 22/25\n",
      "18/18 - 1s - 38ms/step - accuracy: 0.6440 - loss: 2.6585\n",
      "Epoch 23/25\n",
      "18/18 - 1s - 38ms/step - accuracy: 0.6440 - loss: 2.6569\n",
      "Epoch 24/25\n",
      "18/18 - 1s - 37ms/step - accuracy: 0.6440 - loss: 2.6551\n",
      "Epoch 25/25\n",
      "18/18 - 1s - 36ms/step - accuracy: 0.6440 - loss: 2.6534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b599a528c0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the data\n",
    "\n",
    "model.fit(X_train, y_train_one_hot, batch_size=batch_size, epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8bf79704-bb2f-4034-8d3a-ffcfc232ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of stations names\n",
    "\n",
    "stations = {\n",
    "0: 'BASEL',\n",
    "1: 'BELGRADE',\n",
    "2: 'BUDAPEST',\n",
    "3: 'DEBILT',\n",
    "4: 'DUSSELDORF',\n",
    "5: 'HEATHROW',\n",
    "6: 'KASSEL',\n",
    "7: 'LJUBLJANA',\n",
    "8: 'MAASTRICHT',\n",
    "9: 'MADRID',\n",
    "10: 'MUNCHENB',\n",
    "11: 'OSLO',\n",
    "12: 'SONNBLICK',\n",
    "13: 'STOCKHOLM',\n",
    "14: 'VALENTIA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0e6298f0-5f0c-436e-a561-01e27fd73985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred, stations):\n",
    "    # Check if y_true and y_pred are one-hot encoded or already class indices\n",
    "    if y_true.ndim == 1:\n",
    "        y_true_labels = y_true\n",
    "    else:\n",
    "        y_true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred_labels = y_pred\n",
    "    else:\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "    # Map numeric labels to activity names\n",
    "    y_true_series = pd.Series([stations[y] for y in y_true_labels])\n",
    "    y_pred_series = pd.Series([stations[y] for y in y_pred_labels])\n",
    "    \n",
    "    return pd.crosstab(y_true_series, y_pred_series, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6e0d0c46-d700-4d69-95c7-90e5d3fd9ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b2cda9ab-863f-4240-a5df-f5bfecac04c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred        BASEL\n",
      "True             \n",
      "BASEL        3682\n",
      "BELGRADE     1092\n",
      "BUDAPEST      214\n",
      "DEBILT         82\n",
      "DUSSELDORF     29\n",
      "HEATHROW       82\n",
      "KASSEL         11\n",
      "LJUBLJANA      61\n",
      "MAASTRICHT      9\n",
      "MADRID        458\n",
      "MUNCHENB        8\n",
      "OSLO            5\n",
      "STOCKHOLM       4\n",
      "VALENTIA        1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred, stations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c868a2-4127-4c51-ac16-04e2cef94ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aSQ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
